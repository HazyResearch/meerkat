{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Audio Embeddings\n",
    "\n",
    "In this notebook, we will visualize audio embeddings of the HuggingFace Speech Commands dataset.\n",
    "\n",
    "**Dependencies**\n",
    "\n",
    "    # Install UMAP for dimensionality reduction.\n",
    "    pip install umap-learn\n",
    "\n",
    "    # (Optional) If you want to compute embeddings on your own.\n",
    "    # This is not necessary if you are fetching precomputed embeddings.\n",
    "    pip install transformers librosa soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTORCH_ENABLE_MPS_FALLBACK=1\n"
     ]
    }
   ],
   "source": [
    "%set_env PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "import meerkat as mk\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set your device here\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, KeyError found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m mk\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39marxiv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/code/meerkat/meerkat/datasets/__init__.py:124\u001b[0m, in \u001b[0;36mget\u001b[0;34m(name, dataset_dir, version, download_mode, registry, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    121\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid registry: \u001b[39m\u001b[39m{\u001b[39;00mregistry\u001b[39m}\u001b[39;00m\u001b[39m. Must be one of \u001b[39m\u001b[39m{\u001b[39;00mREGISTRIES\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         )\n\u001b[1;32m    123\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo dataset \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m found in registry. Errors:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(errors)\n\u001b[1;32m    125\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, KeyError found"
     ]
    }
   ],
   "source": [
    "df = mk.get(\"arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_draft_year(doc):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(doc)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(APIInfo(api=<fastapi.applications.FastAPI object at 0x16b817d90>, port=5000, server=<meerkat.interactive.server.Server object at 0x12077ef10>, name='127.0.0.1', shared=False, process=None, _url=None),\n",
       " FrontendInfo(package_manager='npm', port=8001, name='localhost', shared=False, process=<Popen: returncode: None args: ['python', '-m', 'http.server', '8001']>, _url=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip the build if you do not have npm installed.\n",
    "mk.gui.start(dev=False, skip_build=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "In this demo, we will be working with [`music_genres_small`](https://huggingface.co/datasets/lewtun/music_genres_small) dataset on HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018494844436645508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading readme",
       "rate": null,
       "total": 487,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1f344e17434976887db524d2c1ad5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/487 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008691787719726562,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094b5d2c21de460fadcbb7bcfbdb80fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabrieyuboglu/code/meerkat/meerkat/columns/scalar/arrow.py:205: UserWarning: Unable to check if column is a valid primary key: Function 'unique' has no kernel matching input types (struct<bytes: binary, path: string>)\n",
      "  warnings.warn(f\"Unable to check if column is a valid primary key: {e}\")\n"
     ]
    }
   ],
   "source": [
    "dataset = mk.get(name=\"lewtun/music_genres_small\", registry=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import datasets as hf_datasets\n",
    "\n",
    "from meerkat.interactive.formatter import AudioFormatterGroup\n",
    "from meerkat.cells.audio import Audio\n",
    "\n",
    "df = dataset[\"train\"].view()\n",
    "\n",
    "# The audio column is a dictionary containing the bytes.\n",
    "# Extract the bytes lazily.\n",
    "# The byte string is actually the fastest way to display the audio,\n",
    "# because the encoding is already done.\n",
    "df[\"audio\"] = df[\"audio\"].defer(lambda x: x[\"bytes\"])\n",
    "\n",
    "# Set the formatter for this column.\n",
    "df[\"audio\"].formatters = AudioFormatterGroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"http://localhost:8000/?id=Table7c69d119-c91d-452c-ba3c-2a957e31b049\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16bb5e760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the dataset with Wav2Vec2\n",
    "Encode the dataset with Wav2Vec2. This will take a few minutes.\n",
    "\n",
    "You can also optionally download the embeddings from huggingface. See the code for how to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007481098175048828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 2875055,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558f8ebcbff240cab96eff2057184780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.88M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tar archive, this may take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "# Download embeddings from huggingface.\n",
    "# If you want to generate your own embeddings, see the rest of this section.\n",
    "df_embed = mk.DataFrame.read(\n",
    "    \"https://huggingface.co/datasets/meerkat-ml/meerkat-dataframes/resolve/main/music_genres_small-wav2vec2-embedded.mk.tar.gz\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meerkat.cells.audio import Audio\n",
    "import datasets as hf_datasets\n",
    "\n",
    "# The sampling rate used by Wav2Vec2.\n",
    "sampling_rate = 16000\n",
    "\n",
    "def to_mk_audio(audio: bytes) -> Audio:\n",
    "    \"\"\"Convert from bytes to Audio object.\"\"\"\n",
    "    audio_dict = hf_datasets.Audio().decode_example({\"path\": None, \"bytes\": audio})\n",
    "    return Audio(data=audio_dict[\"array\"], sampling_rate=audio_dict[\"sampling_rate\"])\n",
    "\n",
    "def to_array(audio: Audio):\n",
    "    \"\"\"Resample the audio to the sampling rate used by Wav2Vec2 and extract the array.\"\"\"\n",
    "    return audio.resample(sampling_rate).data\n",
    "\n",
    "df_embed = df[[\"song_id\", \"audio\"]]\n",
    "df_embed[\"audio\"] = df_embed[\"audio\"].defer(to_mk_audio)\n",
    "df_embed[\"audio_tensor\"] = df_embed[\"audio\"].defer(to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, Wav2Vec2Model\n",
    "\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\", device=device)\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(audio_tensor: torch.Tensor):\n",
    "    audio_tensor = audio_tensor.type(torch.float32).to(device)\n",
    "    inputs = processor(audio_tensor, sampling_rate=sampling_rate, return_tensors=\"pt\", device=device)\n",
    "    inputs[\"input_values\"] = inputs[\"input_values\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    return last_hidden_states.mean(dim=1).squeeze().cpu()\n",
    "\n",
    "df_embed[\"embeddings\"] = df_embed[\"audio_tensor\"].map(embed, use_ray=False, pbar=True)\n",
    "df_embed[\"embeddings\"] = df_embed[\"embeddings\"].to(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the interface\n",
    "Build the interface for visualizing the embeddings.\n",
    "\n",
    "We will first merge the embedding dataframe (`df_embed`) with the dataset dataframe (`df`).\n",
    "Then, we will use UMAP to decompose the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = df.merge(df_embed, on=\"song_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "# Compute umap of embeddings. This may take a few seconds.\n",
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(n_components=2)\n",
    "umap = umap.fit_transform(plot_df[\"embeddings\"])\n",
    "plot_df[\"umap_1\"] = umap[:, 0]\n",
    "plot_df[\"umap_2\"] = umap[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_df.mark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"http://localhost:8001/?id=flexd05c2cab-9b27-4b77-9035-2ec8a2e30193\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x29764b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = mk.gui.plotly.ScatterPlot(df=plot_df, x=\"umap_1\", y=\"umap_2\",)\n",
    "\n",
    "@mk.gui.reactive\n",
    "def filter(selected: list, df: mk.DataFrame):\n",
    "    return df[df.primary_key.isin(selected)]\n",
    "\n",
    "filtered_df = filter(plot.selected, plot_df)\n",
    "table = mk.gui.Table(filtered_df, classes=\"h-full\")\n",
    "\n",
    "mk.gui.html.flex([plot, table], classes=\"h-[600px]\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('meerkat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fab435020311317453f49d9f6bde54424ac28707d23828314f0465c42622dc69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
