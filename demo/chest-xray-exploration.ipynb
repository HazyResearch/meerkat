{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9138f45d-3f1f-425a-99e2-9187c3bc293a",
   "metadata": {},
   "source": [
    "## Meerkat Tutorial: Build Interfaces for Diffusion Models\n",
    "\n",
    "In this demo, we will build an interface (from scratch) for generating chest X-rays with diffusion models.\n",
    "\n",
    "We will use [Roentgen](https://arxiv.org/abs/2211.12737), a Stable Diffusion based model fine-tuned to generate chest X-rays. Model weights can be requested [here](https://t.co/uYEY1cO3SU).\n",
    "\n",
    "This demo also uses the Stanford CheXpert dataset, which can be downloaded [here](https://stanfordmlgroup.github.io/competitions/chexpert/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696c8c63-6b11-413d-bbc7-d97a414c7b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from functools import partialmethod\n",
    "# Disable progress bars globally.\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)\n",
    "\n",
    "from typing import List, Union\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as tv_tfms\n",
    "import PIL\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
    "\n",
    "import uuid\n",
    "\n",
    "import meerkat as mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e496ab0b-cb77-4dc7-b753-f8f70b2b9c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(APIInfo(api=<fastapi.applications.FastAPI object at 0x7f152fcfd760>, port=8886, server=<meerkat.interactive.server.Server object at 0x7f16200b2c10>, name='127.0.0.1', shared=False, process=None, _url=None),\n",
       " FrontendInfo(package_manager='npm', port=8887, name='localhost', shared=False, process=<Popen: returncode: None args: ['python', '-m', 'http.server', '8887']>, _url=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the server\n",
    "# If you are on a remote machine, you will need to forward these ports to your local machine.\n",
    "mk.gui.start(dev=False, skip_build=True, api_port=8886, frontend_port=8887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bbf8c9f-7bac-48a8-988a-cf9b17c7106b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The path to the model weights.\n",
    "model_path = os.path.expanduser(\"~/models/roentgen\")\n",
    "\n",
    "# The path to cache results from this demo.\n",
    "cache_path = os.path.expanduser(\"~/.cache/images/roentgen\")\n",
    "\n",
    "# The path to chexpert dataset.\n",
    "chexpert_path = os.path.expanduser(\"~/datasets/CheXpert-v1.0-small\")\n",
    "\n",
    "# We recommend using a cuda device.\n",
    "device = \"cuda\"  # or mps, cpu..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0fad249-d7ea-44e1-8af0-9299d1f5bfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roentgen_text2img: StableDiffusionPipeline = None\n",
    "roentgen_img2img: StableDiffusionImg2ImgPipeline\n",
    "\n",
    "def _load_roentgen():\n",
    "    \"\"\"Load the roentgen pipelines if they haven't been loaded yet.\n",
    "    \"\"\"\n",
    "    global roentgen_text2img, roentgen_img2img\n",
    "\n",
    "    if roentgen_text2img is not None and roentgen_img2img is not None:\n",
    "        return\n",
    "\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_path).to(torch.float32).to(device)\n",
    "    pipe.safety_checker = lambda images, clip_input: (images, False)\n",
    "    \n",
    "    roentgen_text2img = pipe\n",
    "    \n",
    "    roentgen_img2img = StableDiffusionImg2ImgPipeline(\n",
    "        vae=pipe.vae,\n",
    "        text_encoder=pipe.text_encoder,\n",
    "        tokenizer=pipe.tokenizer,\n",
    "        unet=pipe.unet,\n",
    "        scheduler=pipe.scheduler,\n",
    "        safety_checker=pipe.safety_checker,\n",
    "        feature_extractor=pipe.feature_extractor\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f510e18-2487-4ac6-ad56-cc24b58589f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@mk.endpoint()\n",
    "def generate_images(\n",
    "    df: mk.DataFrame,\n",
    "    text: str,\n",
    "    num_images: int,\n",
    "    num_inference_steps: int,\n",
    "    selected: mk.Store[List[str]] = [],\n",
    "    height: int = 512,\n",
    "    width: int = 512,\n",
    "    guidance_scale: float = 4.0,\n",
    "    negative_prompt: str = \"\",\n",
    "):\n",
    "    \"\"\"Generate images from a prompt.\n",
    "\n",
    "    This function is an endpoint that will update the dataframe `df` in-place.\n",
    "\n",
    "    Args:\n",
    "        df: The dataframe to append the new images to.\n",
    "        text: The prompt to generate images from.\n",
    "        num_images: The number of images to generate.\n",
    "        num_inference_steps: The number of inference steps to run.\n",
    "        height: The height of the generated images.\n",
    "        width: The width of the generated images.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        raise ValueError(\"Please enter a prompt.\")\n",
    "    if len(selected) > 1:\n",
    "        raise ValueError(\"Only one image can be selected at a time.\")\n",
    "\n",
    "    _load_roentgen()\n",
    "\n",
    "    prompt = text\n",
    "    num_images = int(num_images)\n",
    "    num_inference_steps = int(num_inference_steps)\n",
    "    \n",
    "    if negative_prompt:\n",
    "        negative_prompt = [negative_prompt]\n",
    "    else:\n",
    "        negative_prompt = None\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"error\")\n",
    "        if len(selected) > 0:\n",
    "            output = roentgen_img2img(\n",
    "                prompt=[prompt],\n",
    "                negative_prompt=negative_prompt,\n",
    "                image=df.loc[selected[0]][\"img\"](),\n",
    "                num_images_per_prompt=num_images,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                guidance_scale=guidance_scale,\n",
    "            )\n",
    "        else:\n",
    "            output = roentgen_text2img(\n",
    "                prompt=[prompt],\n",
    "                negative_prompt=negative_prompt,\n",
    "                num_images_per_prompt=num_images,\n",
    "                num_inference_steps=num_inference_steps,\n",
    "                height=height,\n",
    "                width=width,\n",
    "                guidance_scale=guidance_scale,\n",
    "            )\n",
    "    \n",
    "    os.makedirs(cache_path, exist_ok=True)\n",
    "    paths = []\n",
    "    for i, image in enumerate(output[\"images\"]):\n",
    "        path = os.path.join(cache_path, str(uuid.uuid4()) + \".jpg\")\n",
    "        paths.append(path)\n",
    "        image.save(path)\n",
    "        \n",
    "    # Create a new dataframe with the new images.\n",
    "    time = datetime.now()\n",
    "    new_df = mk.DataFrame(\n",
    "        {\n",
    "            \"Path\": paths,\n",
    "            \"source\": [\"generated\"] * num_images,\n",
    "            \"prompt\": [prompt] * num_images,\n",
    "            # \"num_inference_steps\": [num_inference_steps] * num_images,\n",
    "            # \"time\": [str(time)] * num_images,\n",
    "            # \"prompt_image_ids\": [selected],\n",
    "        }\n",
    "    )\n",
    "    new_df[\"img\"] = mk.files(new_df[\"Path\"], base_dir=\"\")\n",
    "    \n",
    "    # Embed these images with CLIP to make them searchable\n",
    "    new_df[\"img_clip\"] = mk.embed(new_df[\"img\"], encoder=\"clip\", modality=\"image\")\n",
    "    \n",
    "    new_df.set_primary_key(\"Path\")\n",
    "    df.set_primary_key(\"Path\")\n",
    "    if len(df) > 0:\n",
    "        new_df = mk.concat([new_df, df])\n",
    "    new_df.set_primary_key(\"Path\")\n",
    "\n",
    "    df.set(new_df)\n",
    "    if isinstance(selected, mk.Store):\n",
    "        selected.set([])\n",
    "\n",
    "\n",
    "@mk.endpoint()\n",
    "def delete_images(df: mk.DataFrame, selected: mk.Store):\n",
    "    pkeys = [key for key in df.primary_key if key not in selected]\n",
    "    new_df = df.loc[pkeys]\n",
    "\n",
    "    selected.set([])\n",
    "    df.set(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a229d85f-f713-4272-bcbf-9787bbde7b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmrNAS/people/arjun/code/meerkat/meerkat/ops/merge.py:151: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for name, column in merged_df.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# Make a dataframe from the CheXpert dataset.\n",
    "train = mk.DataFrame.from_csv(os.path.join(chexpert_path, \"train.csv\"))\n",
    "valid = mk.DataFrame.from_csv(os.path.join(chexpert_path, \"valid.csv\"))\n",
    "chexpert = mk.concat([train, valid])\n",
    "\n",
    "# Only keep the Path and img columns to simplify adding generated images.\n",
    "chexpert = chexpert[[\"Path\"]]\n",
    "chexpert[\"source\"] = \"chexpert\"\n",
    "chexpert[\"prompt\"] = \"\"  # chexpert scans don't have prompts\n",
    "\n",
    "# Get the clip embeddings.\n",
    "df = mk.read(\"https://huggingface.co/datasets/meerkat-ml/meerkat-dataframes/resolve/main/embeddings/CheXpert-v1.0-small_clip-embeddings.mk.tar.gz\")\n",
    "chexpert = chexpert.merge(df, on=\"Path\")\n",
    "\n",
    "# Add the image column\n",
    "chexpert[\"Path\"] = os.path.dirname(chexpert_path) + \"/\" + chexpert[\"Path\"]\n",
    "chexpert[\"img\"] = mk.files(chexpert[\"Path\"], base_dir=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2470faad-73f4-41fe-be15-156329c213d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chexpert.mark()\n",
    "selected = mk.Store([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af503bec-20a5-49fb-88c7-a5420737a90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bmrNAS/people/arjun/miniconda3/envs/meerkat_env/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 53.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a sample image.\n",
    "generate_images(\n",
    "    df=chexpert,\n",
    "    selected=[],\n",
    "    text=\"small left-sided pleural effusion\",\n",
    "    num_images=1,\n",
    "    num_inference_steps=75,\n",
    "    height=512,\n",
    "    width=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75abee5b-544a-40e0-a7eb-e74e6a55a187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = chexpert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb868d2-2cea-47f8-9eb4-3306d561f060",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a40b835-3f63-4440-a526-11745c7d20a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sliders\n",
    "num_images = mk.gui.Slider(value=1, min=1, max=10, step=1)\n",
    "num_inference_steps = mk.gui.Slider(value=50, min=1, max=200, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f00fba2-d135-4c70-90a7-470921893e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Textboxes\n",
    "prompt = mk.gui.Textbox(\n",
    "    text=\"\",\n",
    "    placeholder=\"Write a prompt...\",\n",
    "    on_keyenter=generate_images.partial(\n",
    "        df=df,\n",
    "        selected=selected,\n",
    "        num_images=num_images.value,\n",
    "        num_inference_steps=num_inference_steps.value\n",
    "    ),\n",
    "    classes=\"grow h-10 px-3 rounded-md shadow-md my-1 border-gray-400 w-full\"\n",
    ")\n",
    "\n",
    "negative_prompt = mk.gui.Textbox(\n",
    "    text=\"\",\n",
    "    placeholder=\"Write a negative prompt (optional)...\",\n",
    "    classes=\"grow h-10 px-3 rounded-md shadow-md my-1 border-gray-400 w-full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3847a39d-15dc-487d-8484-01b8700b46c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Buttons\n",
    "generate = mk.gui.Button(\n",
    "    title=\"Generate\",\n",
    "    icon=\"Magic\",\n",
    "    on_click=generate_images.partial(\n",
    "        df=df,\n",
    "        selected=selected,\n",
    "        num_images=num_images.value,\n",
    "        num_inference_steps=num_inference_steps.value,\n",
    "        text=prompt.text,\n",
    "    ),\n",
    "    classes=\"bg-slate-100 py-1 rounded-md flex flex-col hover:bg-slate-200 w-full\"\n",
    ")\n",
    "\n",
    "delete = mk.gui.Button(\n",
    "    title=\"Delete\",\n",
    "    icon=\"TrashFill\",\n",
    "    on_click = delete_images.partial(df=df, selected=selected),\n",
    "    classes=\"bg-slate-100 py-1 rounded-md flex flex-col hover:bg-slate-200 w-full\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "157e6118-e1af-493f-92de-be99dfa1ebae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gallery\n",
    "gallery = mk.gui.contrib.GalleryQuery(\n",
    "    df=df,\n",
    "    main_column=\"img\",\n",
    "    against=\"img_clip\",\n",
    "    allow_selection=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "848558a0-dd62-422a-999a-56579c93a6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Putting it together.\n",
    "\n",
    "# Overview Panel\n",
    "overview_panel = mk.gui.html.flexcol(\n",
    "    [\n",
    "        mk.gui.Markdown(\n",
    "            \"Generate chest X-rays with [RoentGen](https://arxiv.org/abs/2211.12737)\",\n",
    "            classes=\"font-bold text-slate-600 text-sm\",\n",
    "        ),\n",
    "        mk.gui.Markdown(\n",
    "            \"Specify the impressions to generate (*prompt*) and avoid (*negative prompt*)\",\n",
    "            classes=\"text-slate-600 text-sm\",\n",
    "        ),\n",
    "        prompt,\n",
    "        negative_prompt,\n",
    "        mk.gui.html.gridcols2([generate, delete], classes=\"gap-x-4\"),\n",
    "        # filter,\n",
    "    ],\n",
    "    classes=\"justify-items-start mx-4 gap-1\",\n",
    ")\n",
    "\n",
    "# Slider Panel\n",
    "sliders = mk.gui.html.flexcol(\n",
    "    [\n",
    "        mk.gui.html.grid(\n",
    "            [mk.gui.Markdown(\"Number of images to generate\", classes=\"text-slate-600 text-sm\"), num_images]\n",
    "        ),\n",
    "        mk.gui.html.grid(\n",
    "            [mk.gui.Text(\"Number of diffusion steps\", classes=\"text-slate-600 text-sm\"), num_inference_steps],\n",
    "            \n",
    "        ),\n",
    "    ],\n",
    "    classes=\"items-stretch justify-items-start gap-x-4 gap-y-4 justify-content-space-between\"\n",
    ")\n",
    "\n",
    "view = mk.gui.html.div(\n",
    "    [\n",
    "        mk.gui.html.grid(\n",
    "            [overview_panel, sliders],\n",
    "            classes=\"grid grid-cols-[1fr_1fr] space-x-5\",\n",
    "        ),\n",
    "        gallery\n",
    "    ],\n",
    "    classes=\"gap-4 h-screen grid grid-rows-[auto_1fr]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43ddda47-0ddd-4284-85b9-5dc442bc1c3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"900px\"\n",
       "            src=\"http://localhost:8887/?id=div48d215e0-42ba-463f-8312-d5867ac45f7b\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f149ee07550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Size the window.\n",
    "view._get_ipython_height = lambda: \"900px\"\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a1486a-39a8-40fb-b957-65681e032312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f4ea5afaf573b338e8dc78a4c727c89dcc91951d5042fe52032838707085901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
