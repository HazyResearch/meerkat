{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pathlib\n",
    "base_dir = pathlib.Path(\"/Users/eyubogln/.meerkat/datasets/rfw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing Machine Learning Models with Meerkat \n",
    "\n",
    "\n",
    "In this demo, we’ll be using the Racial Faces in the Wild (RFW) dataset to audit AWS’s FaceCompare API. We provide predictions from the API on this dataset. Your task is to analyze model performance on this dataset and identify slices where the model is performing particularly poorly or particularly well.\n",
    "\n",
    "In order to audit the API, we’ll be using a tool we’re developing that helps data scientists help wrangle and analyze unstructured data: it’s called [Meerkat](https://meerkat.readthedocs.io/en/latest/guide/guide.html). Under the hood, it uses techniques like those described in [Domino](https://meerkat.readthedocs.io/en/latest/guide/guide.html) to identifying underperforming populations in machine learning datasets.\n",
    "\n",
    "So, let’s import the Python package and get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meerkat as mk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Meerkat provides a [registry](https://meerkat.readthedocs.io/en/dev/datasets/datasets.html) of commonly used datasets, like RFW, which allows us to load the data into memory with one line of code.  We can then merge the dataset with a CSV containing the model predictions. \n",
    "\n",
    "In memory, the dataset and model predictions are stored in a [Meerkat DataPanel](https://meerkat.readthedocs.io/en/latest/guide/data_structures.html). A `DataPanel` is in many ways just like a Pandas DataFrame: it’s a tabular data structure made up of columns. Unlike a DataFrame though, the `DataPanel` is designed for unstructured data types like images and audio. As you can see in the table visualization below, there’s a column for the image, the false non-match rate (FNMR), id etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = mk.get(\"rfw\")\n",
    "dp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading CompareFaces Errors**. CompareFaces is an operation in Amazon Rekognition that predicts whether two images are taken of the same person. We've applied CompareFaces v6 (an AWS service) to the RFW dataset and stored the error rates for each image in the file `facecompare_v6_errors.csv`. Specifically, we've computed the *False Non-Match Rate* (FNMR) for each image, a measure of how often the model falsely predicts that two images are **not** of the same person.\n",
    "\n",
    "<div>\n",
    "<img src=\"fnmr.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "We can load these error rates into our DataPanel with a single `DataPanel.merge` call which is equivalent to a `merge` in Pandas or a `join` in SQL. After doing this, we can see that the FNMR for each image is stored in the new `v6_fnmr` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dp.merge(\n",
    "\tmk.DataPanel.from_csv(base_dir / \"themis/facecompare_v6_errors.csv\"),\n",
    "\ton=\"image_id\",\n",
    ")\n",
    "dp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of operations that can be performed on a `DataPanel`, for example, we can use `sample` to randomly shuffle the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dp.sample(frac=1, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "To help with explore datasets with unstructured data types (*e.g.* images), Meerkat allows you to spin up interactive GUIs from within your notebook. These visualizations allow you to efficiently explore large image, audio, and video datasets. \n",
    "\n",
    "Note that the visualizations are highly customizable. There are a few different interface types (*e.g.  “*gallery”, “table”, “plot”) that can be customized from within the notebook.  See the documentation for a full list of interfaces. \n",
    "\n",
    "First though, we'll have to execute the two cells below to launch the interactive mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network, register_api = mk.interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp[\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, understanding the errors, we'll sort the DataPanel by the FNMR column and then launch a new interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dp.sort(by=\"v6_fnmr\", ascending=False) \n",
    "\n",
    "dp.gui.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing global metrics\n",
    "Next we’ll  compute some average metrics across the entire dataset to get a sense of how the model is performing globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fnmr = dp[\"v6_fnmr\"].mean()\n",
    "print(f\"Global False Non-Match Rate: {global_fnmr: .2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing group statistics\n",
    "\n",
    "RFW provides annotations for limited set of high-level racial groups. In ths section, we’ll see how performance varies when stratifying by these groups. To do so, we’ll use `mk.groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = dp.groupby(\"ethnicity\")\n",
    "gb[\"v6_fnmr\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the groups in a `GroupBy` with the `cards` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going beyond available metadata... \n",
    "\n",
    "The trouble is, the subgroup annotations provided in RFW are quite limited. What if there are other groups that we'd like to explore for which we lack annotations?\n",
    "\n",
    "This is where things start to get interesting: we are goinng to use large, pretrained models in order to bootstrap our dataset with more metadata! This is the key idea behind Meerkat.\n",
    "\n",
    "To demonstrate this idea, we've implemented the `match` operation in the GUI. With `match`, we can create new columns by writing natural language queries and matching them to the images. For example, say we want a metadata column that tells us whether the person in the image is wearing sunglasses. We can write a query like: \"A person wearing sunglasses.\"\n",
    "\n",
    "Let's try it out below. First, we'll need to `embed` the images into a latent space using a pretrained encoder (e.g. CLIP). Meerkat includes a registry of available encoders, so we can just specify one in the `mk.embed` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, columns can be embedded using `mk.embed`, however, for time's sake, we'll \n",
    "# just merge in the embeddings below\n",
    "# dp = mk.embed(dp, input=\"image\", num_workers=0, encoder=\"clip\", device=0)\n",
    "\n",
    "dp = dp.merge(\n",
    "    mk.DataPanel.read(base_dir / \"main/rfw_embedded.mk\")[\"image_id\", \"clip(image)\"],\n",
    "    on=\"image_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.gui.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching produces a continuous score for each image in the dataset. We'd like to find a *threshold score* above which people are wearing sunglasses. Using the gallery view we can find this threshold quite easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp[\"sunglasses\"] = dp[\"_match_image_A photo of a person wearing sunglasses.\"] - dp[\"_match_image_A person.\"]\n",
    "dp = dp.sort(by=\"sunglasses\", ascending=False)\n",
    "dp.gui.table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp[\"sunglasses\"] = dp[\"sunglasses\"] > -0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dp.sample(frac=1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = dp.groupby(by=\"sunglasses\")\n",
    "gb[\"v6_fnmr\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.gui.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering slices\n",
    "\n",
    "The subgroup annotations provided in RFW are quite limited, so we’ll use meerkat to *discover* new slices. To do so, we’ll use `dp.explainby`, a method that identifies a set of slices (*i.e.* scalar functions of the `by` column) that explain the variance in the response variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meerkat.ops.sliceby.explainby import explainby\n",
    "\n",
    "# dp = mk.DataPanel.read(base_dir / \"themis/facecompare_v6_global_slices.mk\")\n",
    "\n",
    "indian_dp = dp.lz[dp[\"ethnicity\"] == \"indian\"] \n",
    "\n",
    "eb = explainby(indian_dp, by=\"image\", target=\"v6_fnmr\",  n_slices=10, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\", \"ethnicity\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_dp = indian_dp.sort(by=\"v6_fnmr\", ascending=False)\n",
    "cb = indian_dp.clusterby(by=\"image\")\n",
    "cb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\", \"ethnicity\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving deeper\n",
    "\n",
    "In practice, the slices discovered in the previous section should serve as inspiration for further exploration. One great way to quickly continue exploring other slices is via the plot interface. Unlike standard plotting interfaces, you can actually manipulate the axes and add labels for columns that don’t yet exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_dp.gui.table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_idx = 0\n",
    "indian_dp[f\"slice_{slice_idx}\"] = indian_dp[\"MixtureSlicer(image,v6_fnmr)\"][:, slice_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Demo goals.** The purpose of this demo is to collect feedback on the tools we’re developing. We would like to understand how they can be made more useful for the task of auditing machine learning models. We are still in very early days, so your concerns/suggestions will inform how we move forward. So, please be candid – any and all feedback is appreciated. To help guide the discussion, we’ve included below some specific questions that are particularly front-of-mind for us, but feel free to diverge from these topics:\n",
    "\n",
    "❓ **Questions to Guide Feedback.**\n",
    "\n",
    "*Did you learn something new about the behavior of this algorithm? Did you find slices that you would flag for bias concerns?* \n",
    "\n",
    "*Are these slices actionable? What would that action be? How would you address this slice?* \n",
    "\n",
    "*Did the slices you found seem important/interesting to you? If not, what kinds of slices do you think would be important to find?* *Why do you supect it is hard to find those slices?* \n",
    "\n",
    "Interface Questions\n",
    "\n",
    "- *Did you find the natural language descriptions useful for describing discovered slices, or did just looking through the pictures suffice? Did you trust the descriptions? Concrete examples (ideally with screenshots) would be great here.*\n",
    "- *Did you use natural language to test out new slices? What types of prompts did you write? Did you trust the results?*\n",
    "- *The main interface we currently provide for creating new slices is with natural language? Are there other interfaces you would find useful (*e.g. *scribbling, cropping, upload images)? Were there slices you would’ve liked to test, but weren’t able to?*\n",
    "- *Did you trust the statistics computed on the slices? How can we improve trust? *\n",
    "\n",
    "Implementation Questions:\n",
    "\n",
    "- *For the types of datasets you work with, do you think it would be easy to store it in a Meerkat DataPanel? Does this data structure feel like a good fit? How could it be improved to better support your data?*\n",
    "- *Are there views, plots, visualizations of the data that you were craving?*\n",
    "- *Was it easy to use Meerkat in a Jupyter Notebook?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('domino')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dc70abeb586db4fbbb19fd8ec040a8328b2a3c884b1c8ab3f626b1589cb18a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
