{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pathlib\n",
    "base_dir = pathlib.Path(\"/Users/eyubogln/.meerkat/datasets/rfw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing Machine Learning Models with Meerkat \n",
    "\n",
    "\n",
    "In this demo, we’ll be using the Racial Faces in the Wild (RFW) dataset to audit AWS’s FaceCompare API. We provide predictions from the API on this dataset. Your task is to analyze model performance on this dataset and identify slices where the model is performing particularly poorly or particularly well.\n",
    "\n",
    "In order to audit the API, we’ll be using a tool we’re developing that helps data scientists help wrangle and analyze unstructured data: it’s called Meerkat! Under the hood, it uses techniques like those described in Domino to identifying underperforming populations in machine learning datasets.\n",
    "\n",
    "So, let’s import the Python package and get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meerkat as mk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Meerkat provides a [registry](https://meerkat.readthedocs.io/en/dev/datasets/datasets.html) of commonly used datasets, like RFW, which allows us to load the data into memory with one line of code.  We can then merge the dataset with a CSV containing the model predictions. \n",
    "\n",
    "In memory, the dataset and model predictions are stored in a [Meerkat DataPanel](https://meerkat.readthedocs.io/en/latest/guide/data_structures.html). A `DataPanel` is in many ways just like a Pandas DataFrame: it’s a tabular data structure made up of columns. Unlike a DataFrame though, the `DataPanel` is designed for unstructured data types like images and audio. As you can see in the table visualization below, there’s a column for the image, the false non-match rate (FNMR), id etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = mk.get(\"rfw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading CompareFaces Errors**. CompareFaces is an operation in Amazon Rekognition that predicts whether two images are taken of the same person. We've applied CompareFaces v6 (an AWS service) to the RFW dataset and stored the error rates for each image in the file `facecompare_v6_errors.csv`. Specifically, we've computed the *False Non-Match Rate* (FNMR) for each image, a measure of how often the model falsely predicts that two images are **not** of the same person.\n",
    "\n",
    "<div>\n",
    "<img src=\"fnmr.png\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "We can load these error rates into our DataPanel with a single `DataPanel.merge` call which is equivalent to a `merge` in Pandas or a `join` in SQL. After doing this, we can see that the FNMR for each image is stored in the new `v6_fnmr` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id (PandasSeriesColumn)</th>\n",
       "      <th>identity (PandasSeriesColumn)</th>\n",
       "      <th>ethnicity (PandasSeriesColumn)</th>\n",
       "      <th>image (ImageColumn)</th>\n",
       "      <th>v6_fnmr (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m.0cqh0q_0001</td>\n",
       "      <td>m.0cqh0q</td>\n",
       "      <td>caucasian</td>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m.0cqh0q_0003</td>\n",
       "      <td>m.0cqh0q</td>\n",
       "      <td>caucasian</td>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m.0cqh0q_0004</td>\n",
       "      <td>m.0cqh0q</td>\n",
       "      <td>caucasian</td>\n",
       "      <td><img src=\"data:image/jpeg;base64,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\"></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 3, ncols: 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = dp.merge(\n",
    "\tmk.DataPanel.from_csv(base_dir / \"themis/facecompare_v6_errors.csv\"),\n",
    "\ton=\"image_id\",\n",
    ")\n",
    "dp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of operations that can be performed on a `DataPanel`, for example, we can use `sample` to randomly shuffle the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = dp.sample(frac=1, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "To help with explore datasets with unstructured data types (*e.g.* images), Meerkat allows you to spin up interactive GUIs from within your notebook. These visualizations allow you to efficiently explore large image, audio, and video datasets. \n",
    "\n",
    "Note that the visualizations are highly customizable. There are a few different interface types (*e.g.  “*gallery”, “table”, “plot”) that can be customized from within the notebook.  See the documentation for a full list of interfaces. \n",
    "\n",
    "First though, we'll have to execute the two cells below to launch the interactive mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network, register_api = mk.interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, understanding the errors, we'll sort the DataPanel by the FNMR column and then launch a new interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:7862/interface?id=4760305eb0314d5a8dea9fffe546f79f\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x16c147430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dp = dp.sort(by=\"v6_fnmr\", ascending=False) \n",
    "\n",
    "dp.gui.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing global metrics\n",
    "Next we’ll  compute some average metrics across the entire dataset to get a sense of how the model is performing globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global False Non-Match Rate:  2.28%\n"
     ]
    }
   ],
   "source": [
    "global_fnmr = dp[\"v6_fnmr\"].mean()\n",
    "print(f\"Global False Non-Match Rate: {global_fnmr: .2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing group statistics\n",
    "\n",
    "RFW provides annotations for limited set of high-level racial groups. In ths section, we’ll see how performance varies when stratifying by these groups. To do so, we’ll use `mk.groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v6_fnmr (NumpyArrayColumn)</th>\n",
       "      <th>ethnicity (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011853</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028925</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028373</td>\n",
       "      <td>caucasian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022784</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 4, ncols: 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = dp.groupby(\"ethnicity\")\n",
    "gb[\"v6_fnmr\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11053119731272452"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp[\"v6_fnmr\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the groups in a `GroupBy` with the `cards` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:7862/interface?id=80ebbb36b3dd4611816062a67d3b6726\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13ffce1c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FNMR\n",
      "56180478c7dd4a369d1bcc524aa3a4cc\n",
      "STD FNMR\n",
      "c1a3dba198094bb29bbd47258582cb64\n",
      "Size\n",
      "d2e69bbd82994ef9b99bdb5c355f2db1\n",
      "{\n",
      "  'Mean FNMR': {\n",
      "    dp: {\n",
      "      african: ' 0.011853',\n",
      "      asian: ' 0.028925',\n",
      "      caucasian: ' 0.028373',\n",
      "      indian: ' 0.022784'\n",
      "    }\n",
      "  },\n",
      "  'STD FNMR': {\n",
      "    dp: {\n",
      "      african: ' 0.080372',\n",
      "      asian: ' 0.120433',\n",
      "      caucasian: ' 0.123075',\n",
      "      indian: ' 0.113152'\n",
      "    }\n",
      "  },\n",
      "  Size: {\n",
      "    dp: {\n",
      "      african: ' 10414',\n",
      "      asian: ' 9687',\n",
      "      caucasian: ' 10194',\n",
      "      indian: ' 10307'\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "gb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going beyond available metadata... \n",
    "\n",
    "The trouble is, the subgroup annotations provided in RFW are quite limited. What if there are other groups that we'd like to explore for which we lack annotations?\n",
    "\n",
    "This is where things start to get interesting: we are goinng to use large, pretrained models in order to bootstrap our dataset with more metadata! This is the key idea behind Meerkat.\n",
    "\n",
    "To demonstrate this idea, we've implemented the `match` operation in the GUI. With `match`, we can create new columns by writing natural language queries and matching them to the images. For example, say we want a metadata column that tells us whether the person in the image is wearing sunglasses. We can write a query like: \"A person wearing sunglasses.\"\n",
    "\n",
    "Let's try it out below. First, we'll need to `embed` the images into a latent space using a pretrained encoder (e.g. CLIP). Meerkat includes a registry of available encoders, so we can just specify one in the `mk.embed` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, columns can be embedded using `mk.embed`, however, for time's sake, we'll \n",
    "# just merge in the embeddings below\n",
    "# dp = mk.embed(dp, input=\"image\", num_workers=0, encoder=\"clip\", device=0)\n",
    "\n",
    "dp = dp.merge(\n",
    "    mk.DataPanel.read(base_dir / \"main/rfw_embedded.mk\")[\"image_id\", \"clip(image)\"],\n",
    "    on=\"image_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going beyond available metadata... \n",
    "\n",
    "The trouble is, the subgroup annotations provided in RFW are quite limited. What if there are other groups that we'd like to explore for which we lack annotations?\n",
    "\n",
    "This is where things start to get interesting: we are goinng to use large, pretrained models in order to bootstrap our dataset with more metadata! This is the key idea behind Meerkat.\n",
    "\n",
    "To demonstrate this idea, we've implemented the `match` operation in the GUI. With `match`, we can create new columns by writing natural language queries and matching them to the images. For example, say we want a metadata column that tells us whether the person in the image is wearing sunglasses. We can write a query like: \"A person wearing sunglasses.\"\n",
    "\n",
    "Let's try it out below. First, we'll need to `embed` the images into a latent space using a pretrained encoder (e.g. CLIP). Meerkat includes a registry of available encoders, so we can just specify one in the `mk.embed` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:7862/interface?id=2032f23496f5408bab21cdaa96900870\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13ff95f40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700a43c103c6430e9aca0ca40e22ae07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dp.gui.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching produces a continuous score for each image in the dataset. We'd like to find a *threshold score* above which people are wearing sunglasses. Using the gallery view we can find this threshold quite easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_we need to find the threshold \n",
    "dp = dp[\"sunglasses\"] > 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dp.gui.plot(suggestions=[sb, \"pca\", \"umap\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering slices\n",
    "\n",
    "The subgroup annotations provided in RFW are quite limited, so we’ll use meerkat to *discover* new slices. To do so, we’ll use `dp.explainby`, a method that identifies a set of slices (*i.e.* scalar functions of the `by` column) that explain the variance in the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meerkat.ops.sliceby.explainby import explainby\n",
    "eb = explainby(dp, by=\"image\", target=\"v6_fnmr\",  n_slices=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\", \"ethnicity\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:7863/interface?id=3e4d50ed6f614193b2df49d0d3c3e402\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x147f553d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Mean FNMR\n",
      "88ee3bf064d84aa790c3eb35f91418c1\n",
      "STD FNMR\n",
      "37e23ad83c9d447fbc1f8902817fb873\n",
      "Size\n",
      "e3e307ee59934a82bb3f6b58edad99a5\n",
      "{\n",
      "  'Mean FNMR': {\n",
      "    dp: {\n",
      "      african: ' 0.011853',\n",
      "      asian: ' 0.028925',\n",
      "      caucasian: ' 0.028373',\n",
      "      indian: ' 0.022784'\n",
      "    }\n",
      "  },\n",
      "  'STD FNMR': {\n",
      "    dp: {\n",
      "      african: ' 0.080368',\n",
      "      asian: ' 0.120427',\n",
      "      caucasian: ' 0.123069',\n",
      "      indian: ' 0.113147'\n",
      "    }\n",
      "  },\n",
      "  Size: {\n",
      "    dp: {\n",
      "      african: ' 10414',\n",
      "      asian: ' 9687',\n",
      "      caucasian: ' 10194',\n",
      "      indian: ' 10307'\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cb = dp.clusterby(by=\"image\")\n",
    "cb.gui.cards(\n",
    "    main_column=\"image\", \n",
    "    tag_columns=[\"v6_fnmr\", \"ethnicity\"],\n",
    "    aggregations={\n",
    "        \"Mean FNMR\": lambda x: x[\"v6_fnmr\"].mean(),\n",
    "        \"STD FNMR\": lambda x: x[\"v6_fnmr\"].std(),\n",
    "        \"Size\": len,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diving deeper\n",
    "\n",
    "In practice, the slices discovered in the previous section should serve as inspiration for further exploration. One great way to quickly continue exploring other slices is via the plot interface. Unlike standard plotting interfaces, you can actually manipulate the axes and add labels for columns that don’t yet exist. For example, TODO add labeling example.\n",
    "\n",
    "Now we can using the plotting view, we can use it plot anything in our data. Matching + slicing allows to better understand what a slice is. \n",
    "\n",
    "People singing vs. people singing into a microphone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.gui.plot(suggestions=[sb, \"pca\", \"umap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.loom.com/share/9bde7342c0ad4a6290fffe5e322134f3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "So a lot of the stuff that we found, folks on this team have documented (e.g. hats)\n",
    "BUt, hopefully this demo demonstrates that we can like rediscover this very fast. \n",
    "\n",
    "We want to take this \n",
    "\n",
    "This is research: There are a lot of issues with the tool, because based off of flawed models with unkown accuracy. \n",
    "Part of this is to motivate how the underlying stuff needs to improve. \n",
    "How to make the results actionable. And how to certify the findings. \n",
    "\n",
    "Why are we taking this route of building the interaction in – as opposed to developing a better slice discovery method etc. \n",
    "The methods are never going to be perfect, need to have a hands of the wheel mentality. \n",
    "\n",
    "How to blend interaction into that research. \n",
    "\n",
    "\n",
    "Explain to them what we're up to: this is an initial prototype of low hanging fruit. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('domino')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dc70abeb586db4fbbb19fd8ec040a8328b2a3c884b1c8ab3f626b1589cb18a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
