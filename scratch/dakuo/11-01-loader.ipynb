{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meerkat as mk\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354d4a29dbd344a88e4eb9a9fa51003e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# reveal new dataset's attribute and dimensions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# dp=mk.get(\"ngoa\")[\"published_images\"].lz[:2000]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# dp = mk.get(\"imagenette\", version=\"160px\").lz[:2000]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# dp = mk.get(\"imdb\", registry=\"huggingface\") \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dp \u001b[39m=\u001b[39m mk\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcoco\u001b[39;49m\u001b[39m\"\u001b[39;49m, version\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m2014\u001b[39;49m\u001b[39m\"\u001b[39;49m, download_mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mforce\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# NOT WORKING YET \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/meerkat/meerkat/datasets/__init__.py:78\u001b[0m, in \u001b[0;36mget\u001b[0;34m(name, dataset_dir, version, download_mode, registry, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m registry \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmeerkat\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     77\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m     79\u001b[0m             name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m     80\u001b[0m             dataset_dir\u001b[39m=\u001b[39;49mdataset_dir,\n\u001b[1;32m     81\u001b[0m             version\u001b[39m=\u001b[39;49mversion,\n\u001b[1;32m     82\u001b[0m             download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m     83\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m         \u001b[39mreturn\u001b[39;00m dataset\n\u001b[1;32m     86\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/meerkat/meerkat/datasets/registry.py:28\u001b[0m, in \u001b[0;36mRegistry.get\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m     25\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo object named \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m found in \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m registry!\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name)\n\u001b[1;32m     26\u001b[0m     )\n\u001b[0;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m ret(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)()\n",
      "File \u001b[0;32m~/Desktop/meerkat/meerkat/datasets/abstract.py:58\u001b[0m, in \u001b[0;36mDatasetBuilder.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_mode \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mforce\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mextract\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     56\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreuse\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_downloaded()\n\u001b[1;32m     57\u001b[0m     ):\n\u001b[0;32m---> 58\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[1;32m     59\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdump_download_meta()\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_downloaded():\n",
      "File \u001b[0;32m~/Desktop/meerkat/meerkat/datasets/coco/__init__.py:65\u001b[0m, in \u001b[0;36mcoco.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m     \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m---> 65\u001b[0m         downloaded_path \u001b[39m=\u001b[39m download_url(\n\u001b[1;32m     66\u001b[0m             IMAGE_URL\u001b[39m.\u001b[39;49mformat(version\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mversion, split\u001b[39m=\u001b[39;49msplit), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_dir\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m         extract(downloaded_path, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_dir)\n\u001b[1;32m     70\u001b[0m     downloaded_path \u001b[39m=\u001b[39m download_url(\n\u001b[1;32m     71\u001b[0m         TEST_LABEL_URL\u001b[39m.\u001b[39mformat(version\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_dir\n\u001b[1;32m     72\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/meerkat/meerkat/datasets/utils.py:9\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, dataset_dir, force)\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[39m.\u001b[39mmakedirs(dataset_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_from_cache\n\u001b[0;32m----> 9\u001b[0m \u001b[39mreturn\u001b[39;00m get_from_cache(\n\u001b[1;32m     10\u001b[0m     url, cache_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dataset_dir, \u001b[39m\"\u001b[39;49m\u001b[39mdownloads\u001b[39;49m\u001b[39m\"\u001b[39;49m), force_download\u001b[39m=\u001b[39;49mforce\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/meerkat/lib/python3.9/site-packages/datasets/utils/file_utils.py:582\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, use_auth_token, ignore_url_params, download_desc)\u001b[0m\n\u001b[1;32m    580\u001b[0m         ftp_get(url, temp_file)\n\u001b[1;32m    581\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m         http_get(\n\u001b[1;32m    583\u001b[0m             url,\n\u001b[1;32m    584\u001b[0m             temp_file,\n\u001b[1;32m    585\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    586\u001b[0m             resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m    587\u001b[0m             headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    588\u001b[0m             cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[1;32m    589\u001b[0m             max_retries\u001b[39m=\u001b[39;49mmax_retries,\n\u001b[1;32m    590\u001b[0m             desc\u001b[39m=\u001b[39;49mdownload_desc,\n\u001b[1;32m    591\u001b[0m         )\n\u001b[1;32m    593\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mcache_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    594\u001b[0m shutil\u001b[39m.\u001b[39mmove(temp_file\u001b[39m.\u001b[39mname, cache_path)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/meerkat/lib/python3.9/site-packages/datasets/utils/file_utils.py:385\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, cookies, timeout, max_retries, desc)\u001b[0m\n\u001b[1;32m    376\u001b[0m total \u001b[39m=\u001b[39m resume_size \u001b[39m+\u001b[39m \u001b[39mint\u001b[39m(content_length) \u001b[39mif\u001b[39;00m content_length \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m    378\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    383\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m    384\u001b[0m ) \u001b[39mas\u001b[39;00m progress:\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m1024\u001b[39m):\n\u001b[1;32m    386\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n\u001b[1;32m    387\u001b[0m         temp_file\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/meerkat/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/meerkat/lib/python3.9/site-packages/urllib3/response.py:627\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 627\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    629\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    630\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/meerkat/lib/python3.9/site-packages/urllib3/response.py:566\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    563\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    565\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 566\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/meerkat/lib/python3.9/site-packages/urllib3/response.py:507\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\n\u001b[1;32m    501\u001b[0m c_int_max \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m31\u001b[39m \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    503\u001b[0m     (\n\u001b[1;32m    504\u001b[0m         (amt \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m c_int_max)\n\u001b[1;32m    505\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39m>\u001b[39m c_int_max)\n\u001b[1;32m    506\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m util\u001b[39m.\u001b[39mIS_SECURETRANSPORT\n\u001b[1;32m    508\u001b[0m     \u001b[39mand\u001b[39;00m (util\u001b[39m.\u001b[39mIS_PYOPENSSL \u001b[39mor\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[1;32m    509\u001b[0m ):\n\u001b[1;32m    510\u001b[0m     buffer \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m    511\u001b[0m     \u001b[39m# Besides `max_chunk_amt` being a maximum chunk size, it\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[39m# affects memory overhead of reading a response by this\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[39m# method in CPython.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     \u001b[39m# `c_int_max` equal to 2 GiB - 1 byte is the actual maximum\u001b[39;00m\n\u001b[1;32m    515\u001b[0m     \u001b[39m# chunk size that does not lead to an overflow error, but\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[39m# 256 MiB is a compromise.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# reveal new dataset's attribute and dimensions\n",
    "# dp=mk.get(\"ngoa\")[\"published_images\"].lz[:2000]\n",
    "# dp = mk.get(\"imagenette\", version=\"160px\").lz[:2000]\n",
    "# dp = mk.get(\"imdb\", registry=\"huggingface\") \n",
    "# dp = mk.get(\"coco\", version=\"2014\", download_mode=\"force\").lz[:200] # WORKS, but 14 GB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text (ArrowArrayColumn)</th>\n",
       "      <th>label (ArrowArrayColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 2)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp['train'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your paths\n",
    "DATA_DIR = '/Users/dakuowang/Desktop/FairytaleQA_Dataset/'\n",
    "DOC_PATH = DATA_DIR + 'FairytaleQA_Dataset/split_by_origin'\n",
    "SENTENCE_PATH = DATA_DIR + 'FairytaleQA_Dataset_Sentence_Split/split_by_origin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin',\n",
       " '/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC_PATH, SENTENCE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document DataPanel\n",
    "Load in the document data, from the 'FairytaleQA_Dataset/split_by_origin' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path (PandasSeriesColumn)</th>\n",
       "      <th>source (PandasSeriesColumn)</th>\n",
       "      <th>name (PandasSeriesColumn)</th>\n",
       "      <th>id (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/laotsze-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>laotsze-story</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/why-dog-and-cat-are-enemies-questions.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>why-dog-and-cat-are-enemies-questions</td>\n",
       "      <td>chinese-fairybook/why-dog-and-cat-are-enemies-questions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Document DataPanel\n",
    "doc_dp = mk.DataPanel({'path': glob(DOC_PATH + '/*/*.csv')}) # put in a column called 'path' with all the paths to the csv files\n",
    "\n",
    "# Create some useful columns\n",
    "doc_dp['source'] = doc_dp['path'].apply(lambda x: x.split('/')[-2]) # the source of the document e.g. \"anderson-fairybook\"\n",
    "doc_dp['name'] = doc_dp['path'].apply(lambda x: x.split('/')[-1].split('.')[0]) # the name of the document e.g. \"brave-tin-soldier-story.csv\"\n",
    "doc_dp['id'] = doc_dp['source'] + '/' + doc_dp['name'] # the id of the document e.g. \"anderson-fairybook/brave-tin-soldier-story\"\n",
    "\n",
    "doc_dp.head(2) # note that the columns are \"PandasSeriesColumns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dp['type'] = doc_dp['name'].str.split(\"-\").str.get(-1) # the type of document among [story, questions] -- here we use pandas string methods directly on the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path (PandasSeriesColumn)</th>\n",
       "      <th>source (PandasSeriesColumn)</th>\n",
       "      <th>name (PandasSeriesColumn)</th>\n",
       "      <th>id (PandasSeriesColumn)</th>\n",
       "      <th>type (PandasSeriesColumn)</th>\n",
       "      <th>section_dp (ListColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/laotsze-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>laotsze-story</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 5, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/why-dog-and-cat-are-enemies-questions.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>why-dog-and-cat-are-enemies-questions</td>\n",
       "      <td>chinese-fairybook/why-dog-and-cat-are-enemies-questions</td>\n",
       "      <td>questions</td>\n",
       "      <td>DataPanel(nrows: 20, ncols: 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/help-in-need-questions.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>help-in-need-questions</td>\n",
       "      <td>chinese-fairybook/help-in-need-questions</td>\n",
       "      <td>questions</td>\n",
       "      <td>DataPanel(nrows: 28, ncols: 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/the-disowned-princess-questions.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>the-disowned-princess-questions</td>\n",
       "      <td>chinese-fairybook/the-disowned-princess-questions</td>\n",
       "      <td>questions</td>\n",
       "      <td>DataPanel(nrows: 23, ncols: 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 6, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/native-american-fairybook/the-bird-lover-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-bird-lover-story</td>\n",
       "      <td>native-american-fairybook/the-bird-lover-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 17, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/native-american-fairybook/the-celestial-sisters-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-celestial-sisters-story</td>\n",
       "      <td>native-american-fairybook/the-celestial-sisters-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 10, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/native-american-fairybook/white-feather-and-the-six-giants-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>white-feather-and-the-six-giants-story</td>\n",
       "      <td>native-american-fairybook/white-feather-and-the-six-giants-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 14, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/native-american-fairybook/the-enchanted-moccasins-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-enchanted-moccasins-story</td>\n",
       "      <td>native-american-fairybook/the-enchanted-moccasins-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 19, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/native-american-fairybook/the-crane-that-crossed-the-river-questions.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-crane-that-crossed-the-river-questions</td>\n",
       "      <td>native-american-fairybook/the-crane-that-crossed-the-river-questions</td>\n",
       "      <td>questions</td>\n",
       "      <td>DataPanel(nrows: 20, ncols: 15)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 556, ncols: 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we can load each of the CSV files in: each CSV will be loaded as a DataPanel\n",
    "# We can store these DataPanels inside the doc_dp DataPanel i.e. it's nested (this is convenient here)\n",
    "def load_doc_csv(row):\n",
    "    \"\"\"\n",
    "    Loader for a single document csv file. This function takes a row of the doc_dp DataPanel\n",
    "    and returns a DataPanel with the contents of the csv file.\n",
    "\n",
    "    row: a row from the doc_dp DataPanel\n",
    "    \"\"\"\n",
    "    # Load the csv file from disk as a DataPanel\n",
    "    doc_data = mk.DataPanel.from_csv(row['path']) # access the 'path'\n",
    "    # Just add a doc_id column, so we know which document this CSV came from\n",
    "    doc_data['doc_id'] = [row['id']] * len(doc_data) # access the 'id'\n",
    "    return doc_data\n",
    "\n",
    "doc_dp['section_dp'] = doc_dp.map(load_doc_csv) # .map will run the function on each line of the DataPanel and put the result in a new column called 'section_dp'\n",
    "doc_dp # you should see a DataPanel with 6 columns (path, source, name, id, type, section_dp) and 556 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((276, 6), (276, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the doc_dp DataPanel into two DataPanels, one for stories and one for questions\n",
    "story_doc_dp = doc_dp[doc_dp['type'] == 'story']\n",
    "question_doc_dp = doc_dp[doc_dp['type'] == 'questions']\n",
    "story_doc_dp.shape, question_doc_dp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path (PandasSeriesColumn)</th>\n",
       "      <th>source (PandasSeriesColumn)</th>\n",
       "      <th>name (PandasSeriesColumn)</th>\n",
       "      <th>id (PandasSeriesColumn)</th>\n",
       "      <th>type (PandasSeriesColumn)</th>\n",
       "      <th>section_dp (ListColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/laotsze-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>laotsze-story</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 5, ncols: 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset/split_by_origin/chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 6, ncols: 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_doc_dp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section (PandasSeriesColumn)</th>\n",
       "      <th>doc_id (PandasSeriesColumn)</th>\n",
       "      <th>text (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "      <td>Laotsze is really older than heaven and earth put together. He is the Yellow Lord or Ancient, who created this world together with the other four. At various times he has appeared on earth, under various names. His most celebrated incarnation, however, is that of Laotsze, \"The Old Child,\" which name he was given because he made his appearance on earth with white hair.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "      <td>He acquired all sorts of magic powers by means of which he extended his life-span. Once he hired a servant to do his bidding. He agreed to give him a hundred pieces of copper daily; yet he did not pay him, and finally he owed him seven million, two hundred thousand pieces of copper. Then he mounted a black steer and rode to the West. He wanted to take his servant along. But when they reached the Han-Gu pass, the servant refused to go further, and insisted on being paid. Yet Laotsze gave him nothing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Magic: we can now access all the DataPanels inside story_doc_dp, concatenate them and get out a single DataPanel\n",
    "story_doc_sections_dp = mk.concat(story_doc_dp['section_dp'])\n",
    "story_doc_sections_dp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These rows have an extra column, while all the others have 15 columns [ 47 109]\n",
      "The extra column is called {'comments'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer2 (PandasSeriesColumn)</th>\n",
       "      <th>cor_section (PandasSeriesColumn)</th>\n",
       "      <th>answer3 (PandasSeriesColumn)</th>\n",
       "      <th>doc_id (PandasSeriesColumn)</th>\n",
       "      <th>question (PandasSeriesColumn)</th>\n",
       "      <th>local-or-sum (PandasSeriesColumn)</th>\n",
       "      <th>answer1 (PandasSeriesColumn)</th>\n",
       "      <th>answer5 (PandasSeriesColumn)</th>\n",
       "      <th>question_id (PandasSeriesColumn)</th>\n",
       "      <th>attribute2 (PandasSeriesColumn)</th>\n",
       "      <th>answer4 (PandasSeriesColumn)</th>\n",
       "      <th>attribute1 (PandasSeriesColumn)</th>\n",
       "      <th>ex-or-im1 (PandasSeriesColumn)</th>\n",
       "      <th>answer6 (PandasSeriesColumn)</th>\n",
       "      <th>ex-or-im2 (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chinese-fairybook/why-dog-and-cat-are-enemies-questions</td>\n",
       "      <td>Why was it a lucky ring?</td>\n",
       "      <td>local</td>\n",
       "      <td>Whoever owned it always had enough to live on.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whoever owned it always had enough to live on</td>\n",
       "      <td>causal relationship</td>\n",
       "      <td>explicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>explicit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They did not know whoever owned the ring would always have enough to live on.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chinese-fairybook/why-dog-and-cat-are-enemies-questions</td>\n",
       "      <td>Why did the man and his wife sell the ring for a small sum?</td>\n",
       "      <td>local</td>\n",
       "      <td>They did not know that it was a lucky ring.</td>\n",
       "      <td>They did not know it was a lucky ring</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They did not know about the ring's power</td>\n",
       "      <td>causal relationship</td>\n",
       "      <td>implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>implicit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly, we can do this for the question DataPanels\n",
    "try:\n",
    "    # This doesn't work, because a couple of the question DataPanels have different columns\n",
    "    question_doc_sections_dp = mk.concat(question_doc_dp['section_dp'])\n",
    "except:\n",
    "    # We can check which rows have different columns\n",
    "    has_extra_column = np.where(question_doc_dp.map(lambda x: len(x['section_dp'].columns)) == 16)[0]\n",
    "    print(\"These rows have an extra column, while all the others have 15 columns\", has_extra_column) # 47, 109\n",
    "    extra_column_name = set(question_doc_dp[47]['section_dp'].columns) - set(question_doc_dp[0]['section_dp'].columns)\n",
    "    print(\"The extra column is called\", extra_column_name) # called \"comments\"\n",
    "    # We can fix this by dropping the extra column if it exists\n",
    "    question_doc_dp['section_dp'] = question_doc_dp['section_dp'].map(lambda x: x.drop(extra_column_name, check_exists=False))\n",
    "    # Now we can concatenate\n",
    "    question_doc_sections_dp = mk.concat(question_doc_dp['section_dp'])\n",
    "    \n",
    "question_doc_sections_dp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((556, 6), (276, 6), (276, 6), (4071, 3), (10553, 15))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are all the DataPanels we have so far, with their shapes\n",
    "doc_dp.shape, story_doc_dp.shape, question_doc_dp.shape, story_doc_sections_dp.shape, question_doc_sections_dp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence DataPanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path (PandasSeriesColumn)</th>\n",
       "      <th>source (PandasSeriesColumn)</th>\n",
       "      <th>name (PandasSeriesColumn)</th>\n",
       "      <th>id (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/laotsze-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>laotsze-story</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Sentence DataPanel\n",
    "sentence_dp = mk.DataPanel({'path': glob(SENTENCE_PATH + '/*/*.csv')}) # put in a column called 'path' with all the paths to the csv files\n",
    "\n",
    "# Create some useful columns\n",
    "sentence_dp['source'] = sentence_dp['path'].apply(lambda x: x.split('/')[-2]) # the source of the document e.g. \"anderson-fairybook\"\n",
    "sentence_dp['name'] = sentence_dp['path'].apply(lambda x: x.split('/')[-1].split('.')[0]) # the name of the document e.g. \"brave-tin-soldier-story.csv\"\n",
    "sentence_dp['id'] = sentence_dp['source'] + '/' + sentence_dp['name'] # the id of the document e.g. \"anderson-fairybook/brave-tin-soldier-story\"\n",
    "\n",
    "sentence_dp.head(2) # note that the columns are \"PandasSeriesColumns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['story', 'mrs'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_dp['type'] = sentence_dp['name'].str.split(\"-\").str.get(-1) # the type of document among [story, mrs] -- here we use pandas string methods directly on the column\n",
    "sentence_dp['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path (PandasSeriesColumn)</th>\n",
       "      <th>source (PandasSeriesColumn)</th>\n",
       "      <th>name (PandasSeriesColumn)</th>\n",
       "      <th>id (PandasSeriesColumn)</th>\n",
       "      <th>type (PandasSeriesColumn)</th>\n",
       "      <th>sentence_dp (ListColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/laotsze-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>laotsze-story</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 32, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>chinese-fairybook/how-the-river-gods-wedding-was-broken-off-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 45, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/how-the-five-ancients-became-men-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>how-the-five-ancients-became-men-story</td>\n",
       "      <td>chinese-fairybook/how-the-five-ancients-became-men-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 46, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/old-dschang-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>old-dschang-story</td>\n",
       "      <td>chinese-fairybook/old-dschang-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 89, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/chinese-fairybook/how-molo-stole-the-lovely-rose-red-story.csv</td>\n",
       "      <td>chinese-fairybook</td>\n",
       "      <td>how-molo-stole-the-lovely-rose-red-story</td>\n",
       "      <td>chinese-fairybook/how-molo-stole-the-lovely-rose-red-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 72, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/native-american-fairybook/the-winter-spirit-and-his-visitor-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-winter-spirit-and-his-visitor-story</td>\n",
       "      <td>native-american-fairybook/the-winter-spirit-and-his-visitor-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 26, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/native-american-fairybook/the-bird-lover-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-bird-lover-story</td>\n",
       "      <td>native-american-fairybook/the-bird-lover-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 131, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/native-american-fairybook/the-celestial-sisters-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-celestial-sisters-story</td>\n",
       "      <td>native-american-fairybook/the-celestial-sisters-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 115, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/native-american-fairybook/white-feather-and-the-six-giants-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>white-feather-and-the-six-giants-story</td>\n",
       "      <td>native-american-fairybook/white-feather-and-the-six-giants-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 111, ncols: 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>/Users/dakuowang/Desktop/FairytaleQA_Dataset/FairytaleQA_Dataset_Sentence_Split/split_by_origin/native-american-fairybook/the-enchanted-moccasins-story.csv</td>\n",
       "      <td>native-american-fairybook</td>\n",
       "      <td>the-enchanted-moccasins-story</td>\n",
       "      <td>native-american-fairybook/the-enchanted-moccasins-story</td>\n",
       "      <td>story</td>\n",
       "      <td>DataPanel(nrows: 148, ncols: 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 278, ncols: 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we can load each of the CSV files in: each CSV will be loaded as a DataPanel\n",
    "# We can store these DataPanels inside the sentence_dp DataPanel i.e. it's nested (this is convenient here)\n",
    "def load_sentence_csv(row):\n",
    "    \"\"\"\n",
    "    Loader for a single sentence csv file. This function takes a row of the sentence_dp DataPanel\n",
    "    and returns a DataPanel with the contents of the csv file.\n",
    "\n",
    "    row: a row from the sentence_dp DataPanel\n",
    "    \"\"\"\n",
    "    # Load the csv file from disk as a DataPanel\n",
    "    sentence_data = mk.DataPanel.from_csv(row['path']) # access the 'path'\n",
    "    # Just add a sentence_id column, so we know which document this CSV came from\n",
    "    sentence_data['sentence_id'] = [row['id']] * len(sentence_data) # access the 'id'\n",
    "    # Drop the `document_id` column, because we already have the `id` column\n",
    "    sentence_data = sentence_data.drop('document_id')\n",
    "    return sentence_data\n",
    "\n",
    "sentence_dp['sentence_dp'] = sentence_dp.map(load_sentence_csv) # .map will run the function on each line of the DataPanel and put the result in a new column called 'sentence_dp'\n",
    "sentence_dp # you should see a DataPanel with 6 columns (path, source, name, id, type, sentence_dp) and 278 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((276, 6), (2, 6))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the sentence_dp DataPanel into two DataPanels, one for stories and one for mrs\n",
    "story_sentence_dp = sentence_dp[sentence_dp['type'] == 'story']\n",
    "mrs_sentence_dp = sentence_dp[sentence_dp['type'] == 'mrs']\n",
    "story_sentence_dp.shape, mrs_sentence_dp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Like before, we can now access all the DataPanels inside story_sentence_dp, concatenate them and get out a single DataPanel\n",
    "story_sentence_sections_dp = mk.concat(story_sentence_dp['sentence_dp'].filter(lambda x: len(x) > 0)) # need to filter out the empty DataPanels\n",
    "mrs_sentence_sections_dp = mk.concat(mrs_sentence_dp['sentence_dp'].filter(lambda x: len(x) > 0)) # need to filter out the empty DataPanels\n",
    "sentence_sections_dp = mk.concat(sentence_dp['sentence_dp'].filter(lambda x: len(x) > 0)) # need to filter out the empty DataPanels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text (PandasSeriesColumn)</th>\n",
       "      <th>sentence_id (PandasSeriesColumn)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Laotsze is really older than heaven and earth put together.</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is the Yellow Lord or Ancient, who created this world together with the other four.</td>\n",
       "      <td>chinese-fairybook/laotsze-story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataPanel(nrows: 2, ncols: 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_sections_dp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((278, 6), (276, 6), (2, 6), (25213, 2), (169, 2), (25382, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are all the DataPanels we have so far, with their shapes\n",
    "sentence_dp.shape, story_sentence_dp.shape, mrs_sentence_dp.shape, story_sentence_sections_dp.shape, mrs_sentence_sections_dp.shape, sentence_sections_dp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('meerkat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22b84bc4e78a4753ab78d32f159867f12fd2fe27206678e09d262045099c8fb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
